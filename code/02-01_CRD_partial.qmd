---
title: "CRD"
format: html
---

# Introduction  
The goals of this exercise are to:  
- Create an analytical workflow for a CRD design, from data import through publication-ready plot  
- Understand each of its components  
- Talk about some important aspects including   
    - contrast type, 
    - sum-of-squares type
    - deciding how to extract and display model means and pairwise comparisons  

# a) Setup  
Here is where we load the packages we will use.  
```{r setup}
#install.packages("broom")

# Loading packages
library(tidyverse) # for data wrangling and plotting
library(car) # for Anova function
library(broom) # for model residuals extraction
library(emmeans) # for model mean extraction
library(multcomp) # for pairwise comparison letter display
```

```{r data import}
crd_df 

crd_df
```

# b) EDA tables  
```{r summary}
summary(crd_df)
```

```{r glimpse}
glimpse(crd_df)
```

# c) Wrangling  
```{r crd_dfw}
crd_dfw <- crd_df 

crd_dfw
```


```{r crd_dfw}
summary(crd_dfw)
```
Number of replicates: 4  
Number o treatments: 3 N rates x 3 K rates = 9  
Number of observations: 4 x 9 = 36  
Yield: from 2795 to 7445 kg/ha  

# d) EDA plots  
```{r n boxplot}

```

```{r k boxplot}
ggplot(crd_dfw, aes(x = krate_kgha, 
                    y = yield_kgha,
                    color = krate_kgha)) +
  geom_boxplot() +
  geom_jitter() +
  theme(legend.position = "none")
```

```{r nk boxplot}

```

# e) Statistical model  
## Set-to-zero vs. sum-to-zero  
In R, the default contrast type is set-to-zero.  

In research, we normally are interested in sum-to-zero contrasts.  

Below we change the default to sum-to-zero ("contr.sum") before fitting the model.


```{r model}
# Changing to sum-to-zero contrast
options(contrasts = c("contr.sum", "contr.poly"))

# Model fitting
crd_mod 

# Summary
summary(crd_mod)
```

## Model specification tips  
Instead of specifying 
          `nrate_kgha + krate_kgha + nrate_kgha:krate_kgha`,  
we could have just used  
                   `nrate_kgha*krate_kgha`.  

R interprets the `*` as "give me all main effects and interactions".

The more interacting effects a model has, the more efficient using the * becomes.  


# f) ANOVA table  
The `Anova()` function allows us to use **type 3 sum of squares**.  

The common functions `aov()` and `anova()` use type 1 SS, which is the wrong choice IF have unbalanced data.

If data is balanced, type 1 and 3 give same results.  

For sake of peace of mind, it is simpler to just always use type 3.  

```{r ANOVA}

```

Whenever your model has interaction terms, need to look at them first.  

IF interaction term is significant, then you should explore that effect, and not the main effects separately in case they are also significant.    

In our case, we have a **significant effect of the interaction between nrate_kgha and krate_kgha**, and the main effects are not significant.

Therefore, we should extract means and perform pairwise comparisons for the interaction term.

Before we do that, let's check our model assumptions. Remember, a model is only valid for inference (i.e., means and pwc) IF if fulfills the linear model assumptions.  


# g) Linear model assumptions  
## Extracting residuals
First, let's extract our model residuals, and also create studentized residuals.  

```{r crd_resid}
crd_resid 

crd_resid
```

Notice how we have a data frame with the original data rows and columns, plus some extra residual information.  

Now, let's recap the linear model assumptions:  

- Residual independence (no pattern)  
- Residual variance homogeneity (homoscedasticity)  
- Residual normality (discuss this!)  
- Outlier detection (< -3 or > 3)  

## Residual independence  
- For this, we use the **fitted vs. residual plot**.  
- What we want to see: no clear pattern in residuals, random cloud of points.  
- What we do not want to see: clear pattern, for example, quadratic shape.  
- Adding a `geom_smooth()` helps with that conclusion. We want to see the smooth line and error bands comprising 0 on the y axis.  

```{r }

```
Looks great! Next.  

## Residual homoscedasticity  
- For this, we use the **fitted vs. residual plot**.  
- What we want to see: no clear pattern in residuals, random cloud of points.  
- What we do not want to see: residuals increasing as fitted value increases (fan shape).  
- Adding a `geom_smooth()` helps with that conclusion. We want to see the smooth line and error bands comprising 0 on the y axis.  

```{r }
ggplot(crd_resid, aes(x=.fitted, y=.studresid))+
  geom_hline(yintercept = 0, color="red")+
  geom_point(shape = 21,
             fill = "purple", 
             size = 3,
             alpha = .7)+
  geom_smooth()+
  geom_hline(yintercept = c(-3,3), color = "red")+
  theme_bw()
```
Looks great! Next.  

## Residual normality  
- For this, we use the **quantile-quantile (QQ) plot** and **density plot**.    
- What we want to see: residuals centered around 0 and following a normal distribution.  
- What we do not want to see: skewed residuals that do not follow a normal distribution.  

On the QQ plot, we want to see residuals on the black line, meaning they follow their theoretical normal distribution.  
```{r}

```

It's common for some residuals in the tails being off, especially with low N (N=36). Nothing to worry here.  


```{r}


```
Although the density is a bit higher than expected at the tails, it still looks ok.  

Next.  

## Residual outliers  
- For this, we use the **fitted vs. residual plot**.  
- What we want to see: most if not all residuals within [-3,3] on a studentized residual scale.  
- What we do not want to see: too many residuals > 3 or < -3, the farther away form the thresholds the worse.  
- Adding a `geom_hline()` at the thresholds helps to visualize and diagnose.   

```{r}
ggplot(crd_resid, aes(x=.fitted, y=.studresid))+
  geom_hline(yintercept = 0, color="red")+
  geom_point(shape = 21,
             fill = "purple", 
             size = 3,
             alpha = .7)+
  geom_smooth()+
  geom_hline(yintercept = c(-3,3), color = "red")+
  theme_bw()

```
All residuals are within the [-3, 3] interval, so nothing to worry here.  
Now that model assumptions have been checked and met, we can proceed to using the model for inference.  

# h) Model means  
The next step in the workflow is extracting the model means.  

Whenever we are showing means (in tables or plots), we want them to be from a model, and not simply the arithmetic mean in the raw data (like we would get with `group_by()` and `summarise()`).  

This is specially important IF the data is unbalanced (i.e., missing data), in which case model means are DIFFERENT from arithmetic means on raw data. 

Also, when extracting means from an interaction, there are few different ways of doing it, and which one we do depends on the study objectives. Let's explore them below.

```{r interaction means all}
crd_means_all 

crd_means_all
```

```{r interaction means n inside k}
crd_means_nk 

crd_means_nk
```

```{r interaction means k inside n}
crd_means_kn 

crd_means_kn
```

Notice how the 3 different approaches create structure in the mean extraction, which will carry over to the pwc step.  

# i) Pairwise comparisons  
Now that we extracted means, let's perform pairwise comparisons among them.  

First, let's extract means for all 3 types of interaction means extracted above. After that, we'll make a decision on which one to use.

```{r interaction pwc all}
crd_cld_all <- 

crd_cld_all
```

```{r interaction pwc n inside k}
crd_cld_nk <- cld(crd_means_nk, 
                   reversed=T, 
                   adjust="none",
               Letters=letters)

crd_cld_nk
```

```{r interaction pwc k inside n}
crd_cld_kn <- cld(crd_means_kn, 
                   reversed=T, 
                   adjust="none",
               Letters=letters) 

crd_cld_kn
```

Notice how different types of pwc (which are actually coming from differences in how we extracted the means) are testing different hypothesis.  

I would like to test the hypothesis of everything compared to everything else, which corresponds to our first method using `:`. Let's do that below and some light wrangling.    

```{r selected pwc}
crd_cld_selected <- crd_cld_all 

crd_cld_selected
```

## g) Final plot  
Let's plot our results, including both **raw data** (for allowing our audience to inspect data distribution) and **statistical model summary (i.e., letter separation)** for inference purposes.    

```{r crd final plot}

  # Raw data and boxplots  

  # Adding letters

```

Let's make this plot publication ready.  

Also, let's explore some different ways of showing this, and how that may impact interpretation, using facets.  


